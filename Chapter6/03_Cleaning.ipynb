{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using PPSIM\n",
    "specs, streams, model = PPSIM.initialise(pwd());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and Summarisation\n",
    "\n",
    "Follwing the extraction of the data detailed in the [previous notebook](http://localhost:8888/notebooks/Chapter6/02_Extracting.ipynb), we will now clean the datatable, summarise it and add annotations.\n",
    "\n",
    "Let's take a look at the custom-code in [custom_code/cleaning.jl](http://localhost:8888/edit/Chapter6/custom_code/cleaning.jl)\n",
    "\n",
    "It contains a single main function \n",
    "\n",
    "```julia\n",
    "function clean(sourcefile, sinkfile, seqfile, ontology)\n",
    "#...\n",
    "end\n",
    "```\n",
    ", as well as a helperfunction\n",
    "\n",
    "```julia\n",
    "function trimSequence(seq, pos::Int64, leftflank; rightflank = Union{})\n",
    "    if rightflank == Union{}\n",
    "      rightflank = leftflank\n",
    "    end\n",
    "    l = maximum([1, pos - leftflank])\n",
    "    u = minimum([length(seq), pos + rightflank])\n",
    "    n_headingx = -minimum([0, pos - leftflank - 1])\n",
    "    n_tailingx = -minimum([0, length(seq) - (pos + rightflank)])\n",
    "    trimmedseq = (\"_\" ^ n_headingx) * seq[l:u] * (\"_\" ^ n_tailingx)\n",
    "    if length(trimmedseq) != (rightflank + leftflank + 1)\n",
    "        \"Error: $seq\"\n",
    "    end\n",
    "    return(trimmedseq)\n",
    "end\n",
    "```\n",
    "\n",
    "The helperfunction above takes a sequence of aminoacids, a position, and windowsize as arguments and returns the correspondingly \"trimmed\" sequence.\n",
    "\n",
    "The main function `clean()` takes source- and sinkfiles, as well as a two further arguments that specify two further input files that contain a list of protein sequences (`seqfile`), as well as an ontology-table downloaded from the [Panther-database](http://www.pantherdb.org/).\n",
    "\n",
    "Moreover, it accepts two optional arguments that specify the filename of the cleaning-summary and a cutoff defining the minimal acceptable number of datapoints per condition.\n",
    "\n",
    "Fundamentally, the cleaning function filters the dataset and logs the size of the dataset after each filtering step.\n",
    "Then it uses protein-identifiers to add sequence and ontology data to the filtered dataset.\n",
    "\n",
    "The filtering criteria are:\n",
    "\n",
    "**Entries where data on the normalised ratio H/L is missing for any of the three conditions are excluded**\n",
    "```julia\n",
    "  D = D[D[:Control_0] .>= 0, :]\n",
    "  D = D[D[:B55_0] .>= 0, :]\n",
    "  D = D[D[:GWL_0] .>= 0, :]\n",
    "\n",
    "```\n",
    "\n",
    "**Exclude entries that lack a gene-name annotation**\n",
    "```julia\n",
    "  D = D[!isna(D[:Gene_names]), :]\n",
    "```\n",
    "\n",
    "**Exclude entries that do not meet the criterium on minimal number ofrequired datapoints**\n",
    "```julia\n",
    "  sufficient_data = Int64[]\n",
    "  for i in 1:size(D)[1]\n",
    "    n_data = Bool[]\n",
    "    for c in specs.conditions\n",
    "      l = findfirst(names(D), symbol(c * \"_0\"))\n",
    "      u = findfirst(names(D), symbol(c * \"_45\"))\n",
    "      n_data = [n_data; sum(convert(Array, D[i, l:u]) .>= 0) >= cutoff_n_data]\n",
    "    end\n",
    "    if all(n_data)\n",
    "      sufficient_data = [sufficient_data; i]\n",
    "    end\n",
    "  end\n",
    "  D = D[sufficient_data, :]\n",
    "```\n",
    "\n",
    "**Exclude entries that lack crossmixing data**\n",
    "```julia\n",
    "  D = D[D[:CM_Con_L_B55_H_] .>= 0, :]\n",
    "  D = D[D[:CM_Con_H_B55_L_] .>= 0, :]\n",
    "  D = D[D[:CM_Con_L_GWL_H_] .>= 0, :]\n",
    "  D = D[D[:CM_Con_H_GWL_L_] .>= 0, :]\n",
    "```\n",
    "\n",
    "**Exclude entries with normalised rations > 10**\n",
    "```julia\n",
    "  data_ok = Bool[]\n",
    "  for i in 1:size(D)[1]\n",
    "    d = vec(convert(Array, D[i, findfirst(names(D), :Control_0):findfirst(names(D), :GWL_45)]))\n",
    "    data_ok = [data_ok; !any(d .> 10)]\n",
    "  end\n",
    "  D = D[data_ok,:]\n",
    "```\n",
    "\n",
    "The function then adds sequence data and creates a list of proteins to be used as background set in the sequence analysis.\n",
    "Entries for kreatins are excluded, and ontological information is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/home/nbuser/thesis-notebooks/Chapter6/data/cleaned.csv\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define file locations\n",
    "processed = joinpath(specs.sink, \"table_processed.txt\");\n",
    "extracted = joinpath(specs.sink, \"extracted.csv\");\n",
    "sequences = joinpath(specs.sink, \"sequences.json\");\n",
    "ontology = joinpath(specs.sink, \"pantherGeneList.tsv\");\n",
    "cleaned =  joinpath(specs.sink, \"cleaned.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perform cleaning\n",
    "log = clean(extracted, cleaned, sequences, ontology);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of cleaning/summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTED: total number of entries\t46802\n",
      "EXTRACTED: total number of unique peptides\t23401\n",
      "EXTRACTED: entries missing T0 in Control\t30916\n",
      "EXTRACTED: entries missing T0 in B55\t33347\n",
      "EXTRACTED: entries missing T0 in GWL\t33940\n",
      "CLEANING: total number of entries left after removing entries missing T0\t9658\n",
      "CLEANING: total number of unique peptides left after removing entries missing T0\t8236\n",
      "CLEANING: total number of entries left after removing entries with less than 4\t9069\n",
      "CLEANING: total number of unique peptides left after removing entries with less than 4\t7743\n",
      "CLEANING: total number of entries left after removing entries missing CMs involving Control\t7446\n",
      "CLEANING: total number of unique peptides left after removing entries missing CMs involving Control\t6450\n",
      "CLEANING: total number of entries left after removing entries with timepoints > 10\t7424\n",
      "CLEANING: total number of unique peptides left after removing entries with timepoints > 10\t6432\n",
      "CLEANING: total number of entries left after removing Keratin and peptides lacking gene_names\t7391\n",
      "CLEANING: total number of unique peptides left after removing Keratin and peptides lacking gene_names\t6410\n"
     ]
    }
   ],
   "source": [
    "for (k,v) in log\n",
    "    println(k, \"\\t\", v)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.4.6",
   "language": "julia",
   "name": "julia-0.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.4.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
